# 👑키덕키덕👑
### ⌨키보드를 좋아하거나 나만의 키보드를 원하는 사람들을 위한 커스텀 키보드 ${\textsf{\color{green}경매}}$ 사이트
### 📆프로젝트 기간 : 2025/02/10 ~ 2025/03/16


<br>
<p align="center">
<img src="https://github.com/user-attachments/assets/dc439ee5-15c1-4aaa-aa2a-55b673a9da50" height=230px>
<img src="https://github.com/user-attachments/assets/ec984bc9-05f6-4dd5-919d-1383e68e90d1" height=230px>

</p>

<br>

### [📚 키덕키덕 Team Notion 보러가기](https://teamsparta.notion.site/1962dc3ef514803fbe6cc16fbabe39e0)

### [🎬 발표 영상 보러가기](https://www.notion.so/teamsparta/1962dc3ef514803fbe6cc16fbabe39e0?pvs=4#1b82dc3ef5148048991ac21f92fbf7fd)


<br>

---

## 📐 Architecture

<details>
<summary> <Strong>Architecture 보기</Strong> </summary>
  
<br>
<p align="center">
<img src="https://github.com/user-attachments/assets/490f3504-bf8b-473a-b4a1-7845f564abd7" height=450px>




</p>
<br>
<br>
</details>

---

## 💬 ERD

<details>
<summary> <Strong>ERD 보기</Strong></summary>
  
<br>
<br>
<p align="center">
<img src="https://github.com/user-attachments/assets/89c5150c-c2dc-4657-a2a6-e036b7d6969b" height=650px>


</p>
<br>
<br>
</details>


---
## 📃 와이어 프레임

<details>
<summary> <Strong>와이어프레임 보기</Strong> </summary>
  
<br>
<br>
<p align="center">
<img src="https://github.com/user-attachments/assets/a72d4f3e-dc29-4ff3-a8b0-02fce07f1d5e" height=600px>

</p>
<br>
<br>
</details>


---

## 🛠️ 기술 스택
### 🔹 Back-end
<img src="https://img.shields.io/badge/Java-007396?style=for-the-badge&logo=OpenJDK&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/Spring Boot-6DB33F?style=for-the-badge&logo=springboot&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/Gradle-02303A?style=for-the-badge&logo=gradle&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/MySQL-4479A1?style=for-the-badge&logo=mysql&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/Redis-DC382D?style=for-the-badge&logo=redis&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/QueryDSL-FCC624?style=for-the-badge&logoColor=black">&nbsp;
<img src="https://img.shields.io/badge/postman-E34F26?style=for-the-badge&logo=postman&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/jwt-F80000?style=for-the-badge&logo=json web tokens&logoColor=white">&nbsp;
<br>
<img src="https://img.shields.io/badge/stomp-F7DF1E?style=for-the-badge&logoColor=black">&nbsp;
<img src="https://img.shields.io/badge/websocket-F80000?style=for-the-badge&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/rabbitMQ-47A248?style=for-the-badge&logo=rabbitMQ&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/h2-7952B3?style=for-the-badge&logo=h2&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/spring security-000000?style=for-the-badge&logo=spring security&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/spring data jpa-092E20?style=for-the-badge&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/junit5-4053D6?style=for-the-badge&logo=junit5&logoColor=white">
### 🔹 Front-end
<img src="https://img.shields.io/badge/html5-E34F26?style=for-the-badge&logo=html5&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/javascript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black">&nbsp;
<img src="https://img.shields.io/badge/springboot web-6DB33F?style=for-the-badge&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/thymeleaf-7952B3?style=for-the-badge&logo=Thymeleaf&logoColor=white">&nbsp;


### 🔹 infra
<img src="https://img.shields.io/badge/ec2-DC382D?style=for-the-badge&logo=amazonec2&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/rds-47A248?style=for-the-badge&logo=amazonRDS&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/github actions-A86454?style=for-the-badge&logo=githubactions&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/docker-DD0031?style=for-the-badge&logo=docker&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/load balancing-F7DF1E?style=for-the-badge&logo=awselasticloadbalancing&logoColor=black">&nbsp;
<img src="https://img.shields.io/badge/route 53-4053D6?style=for-the-badge&logo=amazon route 53&logoColor=white">&nbsp;
<br>
<img src="https://img.shields.io/badge/iam-010101?style=for-the-badge&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/google smtp-F80000?style=for-the-badge&logo=google&logoColor=white">&nbsp;



### 🔹 Collaborative Tool
<img src="https://img.shields.io/badge/IntelliJ IDEA-000000?style=for-the-badge&logo=IntelliJ IDEA&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/Github-181717?style=for-the-badge&logo=github&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/git-F05032?style=for-the-badge&logo=git&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/Slack-4A154B?style=for-the-badge&logo=Slack&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/notion-4053D6?style=for-the-badge&logo=notion&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/figma-339AF0?style=for-the-badge&logo=figma&logoColor=white">&nbsp;
<img src="https://img.shields.io/badge/zep-7952B3?style=for-the-badge&logoColor=white">&nbsp;

<br>

---
## 🖥 **주요 기능**

<details>
  <summary><strong>✅ 서비스</strong></summary>

- 인증/인가 : Spring Security
- 회원 관리 : C, R, U, D
- 키보드 관리 : C, R, U, D
- 경매 관리 : C, R, U
- 입찰 : C
    - 비정상적인 입찰 방지
        - 하나의 경매에 최대 10회까지만 입찰 가능
        - 한 번의 입찰에 가능한 입찰 금액은 현재가 + 최소 입찰단위 * 10
- 경매 포인트 충전 : 토스페이먼츠
- 이메일 알림 서비스 : 포인트 결제내역 및 경매 낙찰, 경매 시작/종료 시 알림성 이메일 전송
- 스케줄러 : 경매 시작, 종료 자동 관리

</details>

<details>
  <summary><strong>✅ 인프라</strong></summary>

- CI/CD :
    - Github Actions을 통한 테스트 및 빌드
    - Docker 컨테이너 생성 및 EC2에서 실행
- AWS
    - ROUTE53 : 구매한 도메인의 ENS 관리 및 트래픽 라우팅
    - ALB : 트래픽 분산 및 SSL 인증
    - EC2 : 애플리케이션 배포 및 실행
    - RDS : 회원, 키보드, 경매, 포인트, 입찰 데이터 저장 및 관리

</details>
    
<br>



## ❓기술적 의사 결정❓
<details>
  <summary> <strong> 🔹 GitHubAction</strong> </summary>
  <br>

[구현한 기능]

- GitHub를 활용한 CI/CD (지속적 통합/지속적 배포) 파이프라인을 구현했습니다.

[주요 로직]

- main 브랜치로 Pull Request가 생성 → 테스트를 실행
- 생성된 Pull Request가 Merge → 배포 프로세스 실행
- GitHub Secrets 활용 → EC2 설정을 비공개로 관리
- Docker로 애플리케이션을 컨테이너화하여 EC2에 자동 배포

[배경]

- 수동 배포의 비효율성 : 코드 변경시마다 EC2에 직접 접속하여 수동으로 배포해야 하는 번거로움이 있었습니다.
  
- 테스트 검증 부재 : 배포 전 전체 테스트 코드를 실행하여 검증하는 과정이 체계화 되어있지 않아 버그가 포함된
   <br>
  코드가 실제 서비스에 배포될 위험이 있었습니다.
  
- 배포 과정의 프로세스 확립 : 배포 단계에서 명령어를 잘못 친다던가 하는 휴먼 에러가 발생하여 일관된
  배포 프로세스가 필요하다고 생각했습니다.

[요구사항]

- main으로 Pull Request를 생성했을 때 테스트 코드를 확인하여야 합니다.
- main으로 Merge가 되었을 때 배포가 되어야 합니다.
- 프로그램이 Docker 컨테이너 위에서 실행되어야 합니다.

[선택지]

- Jenkins
- GitHub Actions  🥕

[의사결정/사유]

- 기존에 GitHub Actions를 활용한 CI/CD 구축 경험이 있어 새로운 도구를 학습하는 데 드는 리소스를 고려했을 때
  <br>
  가장 효율적인 선택이었습니다.
- 프로젝트가 GitHub에서 관리되고 있어 별도의 외부 서비스 없이 GitHub 내에서 CI/CD를 구현할 수 있다는 점이
  <br>
  강점이었습니다.
- GitHub Actions는 YAML 파일을 기반으로 워크플로우를 정의할 수 있어 구현이 용이하고 유지보수 부담이
  <br>
  적었습니다.

[회고]

- 단일 서버 환경일때 구현을 해 배포를 해보았으나 시간이 없어 다중 서버 환경일 때 CI&CD 구축을 경험하지 못해 아쉬움이 남습니다.
- 직접 EC2에 파일을 전송하는 방법을 택했으나 다음에는 S3를 이용하는 방식도 고려해보고 싶습니다.
    
</details>

<details>
  <summary> <strong>🔹 토큰 블랙리스트 등록에 Redis 캐시를 사용한 이유</strong> </summary>
  <br>

  [구현한 기능]

- 회원 탈퇴 시, 해당 사용자의 토큰을 블랙리스트에 등록하여 더 이상 사용할 수 없도록 처리하는 기능을

  구현했습니다. 

[주요 로직] → 흐름도 작성

- 회원 탈퇴 요청 → 사용자 정보 삭제 및 토큰을 블랙리스트에 등록
- 사용자가 서비스 요청 → 요청의 토큰이 블랙리스트에 포함되어 있는지 검증
- 블랙리스트에 포함된 토큰 → 요청 거부
- 토큰 만료 시 → 블랙리스트에서 자동 삭제

  <img src="https://github.com/user-attachments/assets/f1240532-171a-4aa9-bb1a-de06c1d25a65" height=300px>




[배경]

- 회원 탈퇴 후에도 토큰에 대한 정보를 알고 있다면 토큰이 만료될 때까지 서비스를 계속 이용할 수 있는 문제가

  있었습니다. 이를 해결하기 위해 블랙리스트를 도입하여, 탈퇴 시 해당 토큰을 블랙리스트에 등록하고 이후

  모든 요청에서 블랙리스트에 포함되어 있는지 확인하는 방식으로 차단했습니다.

[요구사항]

- 블랙리스트는 일정 시간(토큰의 유효기간) 이후 자동으로 만료되도록 관리해야 합니다.
- 블랙리스트 조회는 Filter를 지나기 때문에 빨라야 합니다.

[선택지] 

- Redis 🥕
    - 다중 서버 환경에서도 일관된 데이터 관리를 보장할 수 있음
    - 네트워크를 통해 데이터를 공유하므로 캐시 일관성 유지 가능
    - 요청이 발생할 때마다 네트워크 호출이 필요 → 응답 속도 저하 가능
    - 로컬 캐시에 비해 상대적으로 높은 네트워크 비용 발생
- Caffeine
    - 성능이 뛰어나고 빠른 응답 속도 제공
    - 구현이 간단하고 사용하기 쉬움
    - 로컬 캐시 방식이라 네트워크 호출이 없어 비용이 적음
    - 다중 서버 환경에서 일관성이 보장되지 않음
    - 서버별로 캐시 데이터가 달라질 수 있어 신뢰도가 낮아질 가능성 있음

[의사결정/사유]

- 블랙리스트 조회는 모든 요청마다 수행되므로, 매번 네트워크 호출이 필요해 응답 속도가 느려질 가능성이 있음
- 처음에는 성능이 뛰어난 Caffeine을 사용했으나, 다중 서버 환경에서 캐시 데이터가 일관되지 않을 가능성이 있음
- 결과적으로, 데이터 일관성을 보장하기 위해 Redis를 선택함

[회고]
  
- 시간이 없어 기존에 사용해본 Redis를 사용해봤지만 다중 서버 환경에서의 다른 캐시 방법을 찾아보고 싶습니다.

</details>


<details>
  <summary> <strong>🔹 QueryDSL</strong> </summary>
  <br>

  [구현한 기능]

- 경매 다건 조회 기능에 QueryDSL 이용하여 다양한 옵션으로 선택적 검색이 가능 하도록 구현하였습니다. 

[주요 로직]

1. 설정한 옵션에 해당하는 결과만 출력하도록 하였습니다. 
2. DTO방식을 이용하여 불필요한 컬럼은 조회하지 않도록 하였습니다. 
3. @QueryProjection 을 이용하여 런타임 시점이 아닌 컴파일 시점에 
    
    오류를 잡아낼 수 있도록 하였습니다.  
    

[배경]

- 초기에 구현했던 경매 목록 조회 기능은 별도의 검색 옵션이 없는 전체 목록 조회였습니다. 

   조회 기능에 관하여 생각을 하던 도중 인스타그램을 통해 어렴풋이 기억나는 단어에 대해서 검색을 했을 때 

   원하는 결과 값이 나와서 도움이 되었던 기억이 스쳤습니다. 저희 로직도 그러한 방식으로 검색을 할 수 있다면 

   좋을 것 같아서 구현하게 되었습니다.  

[요구 사항]

1. 동적쿼리
    1. 사용자가 어떠한 것을 검색하던 편리하게 검색 할 수 있어야 하며,
        
        결과 값이 정확히 나오도록 설계해야 한다고 생각했습니다. 
        
2. 유지보수성
    1. 개발자 측면에서 검색 옵션이 추가되거나, 삭제되더라도
        
        변경을 쉽고 빠르게 할 수 있어야 한다고 생각했습니다. 
        
3. 타입 안전성
    1. 쿼리 작성 시 발생할 수 있는 오류들에 대하여 미리 발견하거나, 
        
        대비할 수 있어야 한다고 생각했습니다.
        

[선택지]

- 각 검색 조건에 해당하는 API를 생성하기
    - 사용자가 검색 할 때에 사용하는 검색 조건 중 가장 많은 빈도를 차지할 것이라고
        
        예상되는 것들에 대한 각 API를 만들어서 이용할 수 있게 하는 방법
        
        - 장점 : 사용자가 원하는 조건에 따른 API를 호출하기 때문에 하나의 API에서
            
          로직에 문제가 발견되더라도 나머지 검색 기능은 정상적으로 작동합니다. 
            
        - 단점 : 검색 조건이 많아질수록 각 조건에 맞는 API를 별도로 생성해 줘야 하며,
            
          중복 로직이 많아지고, 검색 조건이 변경되면 해당하는 여러가지의 API를
            
          수정해야 하므로 유지 보수가 복잡해지게 됩니다. 
            
- JPQL을 이용한 동적 쿼리 만들기
    - JPQL을 이용하여 동적 쿼리를 만들어 검색을 할 수 있는 기능을 만들기
        - 장점 : 자바에서 제공하는 기능이고, 쿼리 메서드 조합을 잘하면 쉽게
            
          구현할 수 있다는 장점이 있습니다. 
            
        - 단점 : 다양한 검색 조건이 들어간 동적 쿼리의 특성 상 쿼리메서드로 만들기엔
            
          한계가 있으며, 문자열로 작성하기 때문에 쿼리문이 복잡해지고, 가독성이
            
          떨어집니다. 또 컴파일러, 컴파일 시점에 오류가 잡기 힘들고
            
          엔티티에 대해 연관된 데이터를 조회하기 위해 추가적인 쿼리가 발생하여
            
          N+1 문제로 인한 성능 저하가 일어날 수 있습니다. 
            
- ✅ QueryDSL을 이용한 동적 쿼리 만들기
    - QueryDSL을 이용하여 동적 쿼리를 만들어 검색할 수 있는 기능 만들기
        - 장점 : 문자열로 작성하지 않고 자바 코드로 작성하기 때문에 잘못된 필드 이름이나
            
          타입 등을 컴파일러를 통해 쉽게 찾아낼 수 있고, 가독성이 올라가며
            
          이해하기 쉽고 수정하기 편하다는 장점이 있습니다. 
            
          또한 @QueryProjection을 통해 컴파일 시점에 오류를 잡을 수 있다는
            
            장점이 있습니다. 
            
        - 단점 : 처음 사용할 때 다소 학습이 필요하고, 별도의 의존성 주입으로 인한
            
          버전 관리, 호환성 문제 등이 있을 수 있습니다. 
            
    

[의사결정/사유]

- 의사결정 : QueryDSL을 이용한 동적 쿼리 만들기
- 사유 : 처음 사용할 때 학습이 필요한 점과 별도의 의존성 주입으로 인한 버전 관리,
    
  호환성 문제 등에 대한 단점이 있지만, 유지 보수성과 타입 안전성 부분에서
    
  다른 방법들에 비해 우수하다고 생각하여 선택하게 되었습니다. 
    

[회고]

- 쿼리 사용이 익숙하지 않아 활용적이지 못한 것 같아 아쉬움이 있습니다. 공부를 더 해서

   아직 모르는 다양한 기능들을 알아보고 보다 효율적으로 코드를 개선해 보고 싶고,

   초성 검색 기능 구현에 대해서도 공부해 보고 싶습니다.
    
</details>

<details>
  <summary> <strong>🔹 페이지 네이션(offset / cursor)</strong> </summary>
  <br>

  [구현한 기능]

- offset기반 페이징과 cursor기반 페이징을 이용하여 모두 구현해 보았으며, 

   검색 속도 개선과  문제 해결을 위하여 결과적으로 cursor기반 페이징을 최종 반영 하였습니다.

[주요 로직]

- QueryDSL을 이용한 조회 기능에 offset기반 페이징 처리를 하여 사용자가 페이지를 선택하여 조회를 할 수 있는

  기능을 1차적으로 구현하여 테스트 진행 후검색 속도 개선과 문제 해결(CountQuery)를 위하여 cursor기반

  페이징을 최종 반영 시켰습니다. 

[배경]

- 검색 기능을 구현한 후 생각을 하던 도중 조회 결과가 한번에 보이는 것은 속도 저하와 사용자의 시각적인

  측면에서 불편함이 발생할 것이라고 생각하여 페이징 처리를 하게 되었습니다. 

[요구 사항]

1. 데이터의 정확성
    1. 사용자가 조회를 하는 도중에 데이터가 추가되거나 삭제되어도 유실, 중복되는 데이터 없이 정확한 정보가
      
       반환되어야 한다고 생각했습니다. 
        
2. 빠른 속도
    1. 어떤 방식으로 조회를 하더라도 빠른 속도를 유지하여 사용자에게 불편함이 없어야 한다고 생각합니다. 
        

[선택지]

- ✅ offset 기반 페이징
    - 조회한 데이터를 “페이지”단위로 구분하여 출력하는 방식
        - 장점 : 사용자가 특정 페이지로 직접 선택하여 이동할 수 있고,
            
          구현이 간단하며, 다양한 정렬 방식을 쉽게 적용할 수 있다는 장점이 있습니다.
            
        - 단점 : 페이지를 불러오는 사이에 데이터의 변화가 있을 경우, 중복 데이터 혹은
            
          유실 데이터가 있을 수 있으며, 요청한 데이터를 바로 조회하는 것이 아니라
            
          이전의 데이터를 모두 조회한 후 offset을 조건으로 잘라내는 방법이기 때문에
            
          offset의 숫자가 커질수록 응답 속도가 느리다는 단점이 있습니다. 
            
- ✅✅ cursor 기반 페이징
    - 무한 스크롤을 구현할 때 흔히 사용하는 방법이기도 하며, 마지막으로 조회된 항목을
        
        기준으로 다음 데이터를 가지고 오는 방식 
        
        - 장점 : offset값을 사용하는 대신 이전에 조회한 마지막 항목을 기준으로 다음 항목을
            
           가지고 오기 때문에 데이터 베이스의 부하가 적고 속도가 빠르며, 데이터에
            
           변화가 있더라도 이전에 조회한 데이터를 기준으로 결과를 반환하므로, 
            
          사용자에게 일관된 결과를 제공한다는 장점이 있습니다. 
            
        - 단점 : 사용자가 원하는 특정 페이지로 직접 이동할 수 없고, 오직 다음 또는 이전
            
          페이지로만 이동할 수 있으며, 구현이 상대적으로 복잡하다는 단점이
            
          있습니다. 
            

[의사결정/사유]

- 의사결정 : offset기반 페이징, cursor기반 페이징
- 사유 :
    - offset기반과 cursor기반에 대해서 공부해 보았지만, 실제로 저의 프로젝트에
        
      적용하였을 때 각 방식에 따른 장단점이 있을 것이라 생각하였으며, 개인적으로
        
      cursor기반 페이징을 경험(실제 웹사이트)해 봤던 기억이 좋지 않았습니다.
        
      지극히 개인적인 생각이기 때문에 프로젝트에 바로 그 의견을 적용하긴 어려워서
        
      두 가지 방법 모두 구현을 해본 후 더 적합한 것을 선택하고자 하였습니다. 
        
    

[회고]

- offset기반 페이징과 cursor기반 페이징을 모두 구현해보면서 각자 어떤식으로 작동을

   하는지에 대해 직접 확인해 볼 수 있어서 좋았고, 구현하면서 생긴 문제들에 대해서 

   조금 더 공부해볼 생각을 하니 기대됩니다.
  
    
</details>

<details>
  <summary> <strong>🔹 Full Text Index</strong> </summary>
  <br>

  [구현한 기능]

- full text index를 적용하여 검색 응답 속도 개선을 하였습니다. 

[주요 로직]

- 기존에 사용한 like연산자를 이용한 검색에 대한 속도를 개선하고자, full text index 적용 후 사용자 정의 함수를

  사용하여 match...aganist로 응답속도를 개선했습니다. 

[배경]

- 검색은 정확한 정보를 응답하는 것도 중요하지만 응답 속도 또한 중요하다고 생각하였습니다. 

   키보드 100만 건을 기준으로 키보드 이름에 대해서 검색을 해보았습니다.

- 검색조건 :
    - 키보드 이름 : red가 들어간 키보드 조회
    - offset기반 페이징
    - 한 페이지에 50개 출력
    - 10번 째 페이지 선택
    - 결과에 충족하는 총 데이터 수 32,491건
      
      <img src="https://github.com/user-attachments/assets/172a37e5-b432-423d-a726-dc1ef58db07f" height=350px>
      


   단순히 눈으로 보이는 1초는 빠르다고 느껴질 수 있으나 응답을 기다릴 때 체감 상 빠르다고 생각이 들지 않았습니다.

  해당 기능을 구현한 사람의 입장에서도 다소 답답함이 느껴진다면 사용자의 입장에서는 더욱 답답할 것이라고 생각하였고, 

  그로 인해 응답 속도를 개선하고자 하였습니다. 

[요구 사항]

1. 빠른 속도
   
    1. 사용자가 불편함을 겪지 않도록 응답 속도가 중요하다고 생각했습니다.
       
3. 정확한 반환 값
   
    1. 속도가 빠르지만, 검색어에 연관 없는 데이터가 반환 된다면 아무 의미가 없다고
        
        생각 하기 때문에 데이터 정확성이 중요하다고 생각했습니다.
        
         
        

[선택지]

1. like 연산자 수정
    1. 기존에 작성되어있는 like연산자에서 앞 부분에 있는 %를 제외하여 해당 컬럼을 인덱싱 처리하여
      
       접두어 검색
        
        ```java
        // 기존 코드
        private BooleanExpression auctionTitle(String auctionTitle) {
            if (auctionTitle == null) {
                return null;
            }
        
            return auction.title.like("%" + auctionTitle + "%");
        }
        ```
        
        ```java
        // 변경 코드
        private BooleanExpression auctionTitle(String auctionTitle) {
            if (auctionTitle == null) {
                return null;
            }
        
            return auction.title.like(auctionTitle + "%");
        }
        ```
        

- 장점 : 해당 방법을 사용하기 위한 수정이나, 적용이 어렵지 않고 FTS보다 저장 공간을 적게 차지한다는

  장점이 있습니다. 
    
- 단점 : 접두어 검색이기 때문에 사용자가 원하는 포괄적인 검색이 불가능합니다. 예를 들어 “사과”로 검색했을 때

     “사과맛 음료”는 찾을 수 있지만 “맛있는 사과”는 찾을 수 없습니다. 
    
1. full text index
   
    1. 해당하는 컬럼에 full text index처리를 하여 전체 텍스트를 검색 할 수 있도록 구현
        - 장점 : 파서가 문자열을 Tokenizing(문자열을 의미 있는 단위로 분리)하여 인덱스를
            
          생성하므로 검색 속도가 향상 되며, 파서의 종류를 선택하여 tokenizing
            
          할 수 있기 때문에 검색의 폭이 넓어질 수 있습니다. 
            
        - 단점 : 데이터를 모든 단어별로 분리하여 저장하기 때문에 저장 공간이 많이
            
          필요하며, 잦은 데이터 변화가 있을 시 오버헤드가 발생할 수 있다는 단점이
            
          있습니다. 또한 QueryDSL은 RDBMS(관계형 데이터베이스 관리 시스템)를
            
          따르기 때문에 FTS(Full Text Search)를 네이티브하게 지원하지 않아  
            
          사용자 정의 함수를 이용하여 구현해야 한다는 단점이 있습니다. 
            

[의사결정/사유]

- 의사결정 : full text index
- 사유 :
    - 지금 현재 저희 프로젝트에서는 속도나 정확성, 그리고 사용자가 폭 넓은 검색을
        
      할 수 있어야 한다는 점을 생각하여 full text index를 선택하였습니다.
        
         
        

[회고]

- 기능을 구현하고 테스트를 해봤을 때 속도가 개선된 점을 직접 확인 할 수 있어서 기분이 좋았고, 

   처음 접해보는 사용자 정의 함수 등록을 해볼 수 있어서 뜻 깊은 시간이었던 것 같습니다. 짧은 시간에 알아보고

   공부하여 구현하다보니 부족한 점이 많아 조금 더 개선해 보고 싶습니다. 그리고 FTS(Full Text Search)에

   관해 검색을 하다 보니 엘라스틱서치 라는 기능이 눈에 자주 띄었어서 관련 공부도 해보고 싶습니다.
  
    
</details>

<details>
  <summary> <strong>🔹 Google SMTP</strong> </summary>
  <br>

 [구현한 기능]
 
- 여러가지 알림기능에 활용할 이메일 전송 기능을 구현하였습니다.

[배경]

- 결제가 완료되거나, 포인트가 일정 금액보다 떨어져 입찰 참여가 어려운 상황이거나, 경매가 끝났을때 낙찰자가 

   되었거나, 내가 생성한 경매가 오픈되었거나 하는 상황에서 사용자에게 알림을 보내야 할 필요가 있습니다. 

   여기서 결제 영수증이나 낙찰 알림 등은 실시간으로 바로바로 확인해야하는 내용의 알림이 아니고 시간이 지나도 

   사용자가 필요하지 않아 지우는 것이 아니라면 사라지지 않고 사용자가 필요하면 언제든지 다시 확인할 수

   있어야 하는 종류의 알림이라고 생각했기때문에 이메일로 구현하였습니다.

[주요 로직]

- Spring Mail과 Gmail SMTP를 활용하여 이메일을 발송하는 구조입니다.

   특정 이벤트 발생 시 이메일 전송 요청을 수신하면`EmailService`로 전달하여 이메일을 전송합니다. 

   HTML 템플릿(Thymeleaf) 기반으로 이메일 본문을 생성합니다.

   `JavaMailSender.send(mimeMessage)`를 호출하면 SMTP 서버와 연결한 후, 메일 전송 요청을 Gmail SMTP 서버로

   보내고 이메일을 발송한 후 종료하는 방식으로 처리됩니다. 이메일 전송이 성공하면 로그를 남기고 API 응답을

   반환합니다.

   <img src="https://github.com/user-attachments/assets/adba5ff1-c16f-4362-a916-078e5e1a8212" height=350px>


[요구사항]

1. 이메일을 송신 할 수 있어야합니다.
   
    1. 고객센터를 이메일로 운영하는게 아니므로 수신기능 필요없다고 생각했습니다.
       
3. 이메일을 구축하는데에 너무 많은 리소스가 사용되면 안됩니다.
   
5. 다른 팀원들이 구현된 내용을 하나하나 분석해보지 않아도 쉽게 사용할 수 있어야 합니다.
   
    1. 알림 기능은 다양하게 활용 가능하므로 원한다면 그냥 가져다가 구현할 수 있어야한다고 생각했습니다.

[선택지]

1. 외부 API사용
   
    1. API 방식은 HTTP 기반의 RESTful API를 활용하여 요청을 보내는 방식
       
    3. 장점
        1. 간단한 HTTP요청으로 전송이 가능합니다.
        2. 전송 로그, 열람 추적 등이 가능합니다.
        3. 대량 전송이 가능합니다.
    4. 단점
        1. 비쌉니다.
            1. sendgrid →월 5만건 15달러 20만건 90달러
            2. Mailgun → 월 5만건 35달러 월 250만건 1250달러 
            3. postmark →월 5만건 60달러 12만건 138달러
            4. aws ses → 월 6만건까지는 무료 그 후에는 비용발생
3. SMTP 
    1. SMTP 프로토콜(Simple Mail Transfer Protocol)을 이용하여 메일을 전송 (수신은 X)
        1. SMTP를 직접 구축
            1. 장점: 
                1. 발송량 제한이 없습니다.
            2. 단점
                1. 서버 유지비가 발생합니다.
                2. 유지보수가 어렵습니다.
                3. 설정 난이도가 어렵습니다.
        2. 구글 SMTP를 이용
            1. 장점 :
                1. 설정 난이도가 쉽습니다.
                2. 유지보수, 보안을 구글이 하므로 우리가 하지 않아도 됩니다.
            2. 단점:
                1. 발송량 제한 있습니다. 하루에 500건

[의사결정/사유]

1. aws ses vs 구글 SMTP
    1. aws
        1. 장점
            1. 전송 로그, 열람 추적 등이 가능합니다.
            2. 월 6만건 넘어도 유료지만 보낼 수 있습니다.
        2. 단점
            1. 초기 설정이 구글 SMTP보다 어렵습니다.
    2. 구글 SMTP 🥕
        1. 장점
            1. 초기 설정이 매우 쉽습니다.
        2. 단점
            1. 보낼 수 있는 메일의 양이 매일 500건으로 한정적입니다.

   Gmail SMTP를 활용하여 전송하는 방식을 선택했습니다.

1. 전송로그 열람 추적등은 마케팅 메일이라면 필요할 수도 있지만 우리가 만드는 건 알림메일이므로 중요치 않다고 생각됩니다.
2. 마찬가지로 대량메일 또한, 마케팅 메일이 아니라 알림메일이므로 중요하지 않았습니다.
3. Gmail SMTP를 활용하는 방식이 가장 리소스가 적게 들어갈 수 있다고 생각합니다.

[회고]

- 기술의 장단점
    - 장점
      
    	정말 쉽게 설정이 가능했습니다. 3시간만에 첫 메일을 보내는데에 성공했고, 팀원들에게 간단한 설명만하고

       바로 코드만 보여줘도 다들 금방 이해하고 활용할 수 있었습니다.
  
    - 단점
        
        대량 메일에 어렵다는 점은 지금 단계에서 아무 문제가 없지만 확장 가능성을 생각하면 조금

      불리할 수 있을 것 같습니다.
        

   다시 시도한다면?

 - Gmail을 사용하는 방식은 간단하지만, EC2에서 메일을 전송할 때 일부 계정에서는 Gmail이 이를 이상 로그인으로
 
   판단하여 차단하는 경우가 있었습니다. 따라서 배포 시 AWS와의 호환성을 고려한다면, 다음번에는 AWS SES를

   활용하는 것을 더 적극적으로 고려해볼 수 있을 것 같습니다.
  
    
</details>

<details>
  <summary> <strong>🔹 토스페이먼츠</strong> </summary>
  <br>

  [구현한 기능]

- 입찰 시 필요한 경매 포인트를 충전하기 위한 결제 기능을 구현했습니다.

[주요 로직]

- 선택한 PG사 : 토스페이먼츠
- 결제 요청이 들어오면 결제 정보를 임시로 저장합니다.
    - 결제 정보 전달 시 클라이언트로부터 조작된 데이터인지 검증하는 용도입니다.
- 토스페이먼츠에 결제 승인 요청을 전송합니다.
- 결제 승인 응답이 정상적으로 오면 결제 내역 및 경매 포인트 정보를 DB에 저장합니다.


 <img src="https://github.com/user-attachments/assets/e19c3678-10c1-48f9-9bab-45adf8189e63" height=350px>



[배경]

- 경매의 핵심 기능인 입찰을 구현하기 위해선 결제 기능이 필요하다고 생각했습니다.
- 결제 기능 없이도 경매 시스템을 구현할 수는 있지만 현실성이 부족하다고 판단했기 때문입니다.

[요구사항]

- 결제 기능을 연동하는데 많은 시간이 소요되지 않아야 합니다.
- 다른 팀원들이 구현 내용을 분석하지 않아도 쉽게 사용할 수 있도록 구현해야 합니다.
- 참고 할 수 있는 자료가 많아야 합니다.

[선택지]

- 아임 포트
    - 참고 자료 (샘플 코드, 포스트맨 등) 다수 존재
    - 다양한 PG사를 간단하게 연결 가능
    - 다양한 기능을 API 호출로 사용 가능
    - 서버 - 아임포트 - PG사의 구조
- ✅ 토스 페이먼츠
    - 참고 자료 (샘플 코드, 개발 문의 채널 등) 다수 존재
    - 서버 - 토스페이먼츠의 구조

[의사결정/사유]

- 경매 포인트를 충전하는 단순한 기능이기 때문에 아임 포트의 사용은 과하다고 생각했습니다.
- API 호출로 기능이 완성되어 버린다면 프로젝트를 빠르게 진행할 수는 있지만, 개인이나 팀의 성장에는

  도움이 되지 않는다고 생각했습니다.
  
- 다양한 PG사를 연결할 것이 아니었기 때문에 결제가 완료되기까지 한 단계를 더 거쳐야 한다는 부분이 단점이

  된다고 생각했습니다.

[회고]

- 기술의 장단점
    - 참고 자료가 잘 되어 있어서 연동에 큰 어려움이 없었습니다.
    - 필요한 결제 관련 기능이 있다면 직접 구현해야 합니다.
    - 토스페이먼츠의 결제 위젯을 사용하기 때문에 커스터 마이징이 불가능했습니다. 그래서 서버에서
    
      필요한 데이터가 있다면 다른 방법을 찾아야만 했습니다.
      
- 다시 시도한다면?
    - 다양한 PG사를 연결하는 것이 아니라면 토스페이먼츠를 사용할 것 같습니다.
    - 다만 결제 위젯과 결제 창이라는 두 가지 종류가 있으며 현재는 결제 위젯을 사용하고 있지만, 다음에는
    
      결제 창을 선택할 것 같습니다.
        - 결제 창에서는 원하는 결제 방식만 선택할 수 있습니다.
        - 결제 내역 등을 비롯하여 개발자 센터에서 확인할 수 있는 기능들이 존재합니다.
          
    
</details>

<details>
  <summary> <strong>🔹 RabbitMQ</strong> </summary>
  <br>

  [구현한 기능]

- 재시도를 포함한 결제 승인 요청 실패 시 해당 요청에 대한 보정 작업으로 결제 취소 요청을 처리하는 메시지 큐를 구현했습니다.

[주요 로직]

- 결제 승인 요청을 실행합니다.
    - 재시도의 가능성이 있기 때문에 멱등키를 헤더에 포함시켜 동일한 요청이라는 것을 알려줍니다.
- 결제 승인 요청 실패 시 재시도를 최대 3회 실행합니다.
- 결제 승인 요청을 모두 (기본 요청 1회  + 재시도 3회) 실패하는 경우, 메시지를 발행합니다.
- 메시지가 발행되면 결제 취소 요청을 실행합니다.
    - 재시도의 가능성이 있기 때문에 멱등키를 헤더에 포함시켜 동일한 요청이라는 것을 알려줍니다.
- 결제 취소 요청 실패 시 재시도를 최대 3회 실행합니다.
- 결제 취소 요청을 모두 (기본 요청 1회  + 재시도 최대 3회) 실패하는 경우, DLQ (Dead Letter Queue)로

  메시지를 이동시킵니다.

<img src="https://github.com/user-attachments/assets/f8bb75a9-1d53-4f73-b86a-7aea6e448f0d" height=350px>


[배경]

- 결제가 실패하는 경우 또는 예기치 못한 에러가 발생했을 경우에 대한 예외 처리가 없었습니다.
- 결제 서버에서는 정상적인 처리가 진행됐지만 모종의 이유로 에러가 발생할 경우, 사용자에게서 금액은
  <br>
  차감되지만 포인트는 충전되지 않는 상황이 발생할 수 있습니다.
- 이런 상황을 방지하고자 에러에 대한 예외 처리를 구현하게 되었습니다.

[요구사항]

- 결제 승인 요청이 실패했을 경우에 대한 보정 작업이기 때문에 메시지에 대한 보장성이 높아야 하고 메시지를

  빠르게 소비해야 합니다.
  
- 설정 및 운영이 복잡하지 않아야 합니다.

[선택지]

- ✅ RabbitMQ
    - 장점
        - 메시지를 디스크에 저장하여 데이터 손실 방지 가능(안정성 보장)
        - ACK/NACK 기능을 통해 확실한 메시지 전송 보장
        - 메시지가 브로커에 들어오면 즉시 Consumer가 가져가서 처리
    - 단점
        - 대량 데이터 처리에 비효율적
        - 메시지 브로커가 SPOF(단일 장애점)이 될 가능성 있음

- Kafka
    - 장점
        - 로그 기반 저장으로 대용량 처리 가능
        - 여러 개의 브로커를 사용하여 수평 확장이 우수
        - 특정 시점부터 다시 읽을 수 있기 때문에 재처리 가능
    - 단점
        - Consumer가 메시지를 가져가는 Pull 방식이기 때문에 메시지 처리는 상대적으로 느림
        - 구현이 다소 복잡하며, 설정 및 운영이 RabbitMQ보다 어려울 수 있음

- Redis Pub/Sub
    - 장점
        - 메시지가 메모리에서 즉시 처리되기 때문에 빠름
        - 설정 및 운영이 간단하며 가볍고 사용하기 쉬움
    - 단점
        - 메시지를 소비하지 않으면 사라지기 때문에 메시지를 보장하지 않음
        - 메시지를 소비했을 때 실패한다면 재시도가 불가능함

[의사결정/사유]

- 결제 승인 요청 실패에 대한 보정 작업이기 때문에 메시지에 대한 보장성이 높아야 하고 빠르게 소비할 수 있어야 한다고 생각했습니다.
- 결제 승인 요청이 완전히 실패하는 경우는 많지 않을 것이라고 생각하여 대량 데이터 처리까지는 필요 없다고

  생각했습니다.
- 또한 처음 도입하는 메시지 큐의 구현, 설정, 운영이 어렵다면 빠른 적용이 힘들다고 생각했습니다.

[회고]

- 기술의 장단점
    - 웹페이지에서 MQ에 대한 관리를 할 수 있는 점이 좋았습니다.
    - 큐는 어떤 타입인지, 바인딩 전략은 어느 것인지에 따라 설정이 다르기 때문에 해당 내용을 검색하는 과정이 어려웠습니다.
      
- 다시 시도한다면?
    - 현재는 DLQ에 저장된 메시지에 대한 처리가 없기 때문에 이 부분을 추가 하고 싶습니다.
        - ex) 스케줄러를 활용하여 결제 취소 요청을 재시도
    - 또한 현재는 네트워크 에러인 경우에만 재시도 및 메시지 발행이 되고 있는데, 토스페이먼츠의 에러 코드도
    
      분류를 나눠서재시도 및 메시지 발행이 가능하도록 하고 싶습니다.
  
    
</details>


<br>

## 💥트러블 슈팅💥

<details>
  <summary> <strong>🔹 CI&CD 과정에서 데이터베이스 연결 실패</strong> </summary>
  <br>

  [문제 인식]

- CI&CD 적용 후, 애플리케이션이 Docker 컨테이너에서 실행될 때 RDS(MySQL) 데이터베이스에 연결할 수 없는 

   오류가 발생했습니다. 로그를 확인해보니 다음과 같았습니다.

   ```java
   Caused by: java.sql.SQLException: Access denied for user 'admin'@'172.31.44.3' (using password: YES)
   ```

   조사 결과, .env 파일에서 RDS 비밀번호가 # 문자로 끝나도록 설정되어 있었습니다.

   .env 파일은 #을 주석으로 처리하기 때문에, 기존에 CI&CD를 적용하지 않은 배포 테스트에서도 비밀번호 일부가

   잘못 인식되는 문제가 발생했었고, 이를 방지하기 위해 작은 따옴표(')로 감싸서 설정해 배포에 성공했었습니다.

   하지만, Docker 환경에서 실행할 때도 동일한 오류가 발생했습니다.

   ```java
   MYSQL_PASSWORD='Qwer12!@#'
   ```

[해결 방안]

- MySQL 비밀번호 변경 : 문제를 일으켰던 특수문자 #을 비밀번호에서 제거하고 테스트를 하기로 했습니다.

[해결 과정]

1. MySQL에 접속해 계정 비밀번호를 변경
2. .env 파일에 MYSQL_PASSWORD 부분을 변경된 비밀번호로 변경
3. 변경된 환경 변수를 포함하여 docker container 재시작
4. 이후 앱이 중지되지 않고 정상적으로 동작하는 것을 확인

[해결 결과]

- Docker 환경변수 설정 시 특수문자가 포함될 경우, 안전한 값으로 변경하거나 적절한 Escape 처리가 필요하다는 점을 확인했습니다.
- 다만, 특수문자가 다른 곳에서도 예상치 못한 문제를 일으킬 가능성이 있기 때문에, 앞으로는 데이터베이스
 <br>
  비밀번호를 설정할 때 더욱 신중하게 고려할 계획입니다.
  
</details>

<details>
  <summary> <strong>🔹 경매 단건 조회에서의 현재가 및 입찰 내역 업데이트 문제</strong> </summary>
  <br>

  [문제 인식]
  
- 현재 경매 사이트에서는 사용자가 입찰 화면을 보고 있을 때, ‘현재가’와 ‘입찰 내역’이 실시간으로 

   변경되지 않는 문제가 있었습니다. 사용자가 페이지를 새로고침 해야만 최신 데이터를 확인할 수 있었으며,

   이로 인해 실시간성이 중요한 경매 환경에서 불편함이 발생했습니다.

[해결 방안]

- 이 문제를 해결하기 위해 여러 가지 데이터 업데이트 방식

  (Polling, Long Polling, WebSocket, SSE, GraphQL Subscription)을 비교해 보았습니다.

- Polling 방식
  
   - 클라이언트가 일정 시간마다 서버에 HTTP 요청을 보내 최신 데이터를 가져오는 방식
	- 장점: 구현이 간단하며, 현재 코드에서도 쉽게 적용 가능
	- 단점: 데이터 변경 여부와 관계없이 주기적으로 요청을 보내 비효율적이며, 실시간성을 완전히 보장하지 못함
  
- Long Polling 방식
  
   - 클라이언트가 서버에 요청을 보내면, 서버는 데이터가 변경될 때까지 응답을 지연시킴. 이후 데이터가
   
     변경되면 응답을 보내고, 클라이언트는 다시 새로운 요청을 보냄.
     
	- 장점: Polling보다 불필요한 요청을 줄일 수 있어 서버 리소스를 절약 가능.
	- 단점: 다수의 사용자가 접속하는 경우 매 요청마다 새로운 HTTP 연결이 필요하므로 서버 부하가
 
   		증가할 가능성이 있음
   
- WebSocket 방식
  
   - 클라이언트와 서버 간의 지속적인 연결을 유지해 실시간 양방향 통신 가능
	- 장점: 데이터 변경 시 서버가 즉시 클라이언트에 알릴 수 있어 실시간성 확보
	- 단점: 지속적인 연결이 필요하여 다수의 사용자 접속 시 서버 부하가 증가 가능
   
- SSE (Server-Sent Events) 방식
  
   - 서버에서 클라이언트로만 데이터를 푸시하는 단방향 통신 방식
	- 장점: WebSocket보다 가벼우며, HTTP 기반이므로 브라우저에서 쉽게 사용 가능
	- 단점: 브라우저당 최대 동시 연결 개수 제한이 있으며, 양방향 통신이 불가능
   
- GraphQL Subscription
  
   - WebSocket 기반으로 특정 이벤트가 발생했을 때 클라이언트로 데이터를 전송하는 방식
	- 장점: REST API보다 더 유연하게 데이터 요청 가능, 불필요한 데이터 전송 최소화
	- 단점: GraphQL 서버를 추가로 구축해야 하므로 도입이 복잡할 수 있음

[해결 과정]

- 실시간성이 중요한 경매 시스템의 특성을 고려했을 때, Polling 방식은 네트워크 트래픽 증가로 인해 부적절하며,

     Long Polling은 다수의 사용자가 접속하는 경우 매 요청마다 새로운 HTTP 연결이 필요하므로 서버 부하가 증가할

     가능성이 높았습니다. 따라서, WebSocket 방식을 도입하여 실시간으로 ‘현재가’와 ‘입찰 내역’을 업데이트하도록

    결정했습니다.

[해결 결과]

- 사용자는 페이지 새로고침 없이도 실시간으로 ‘현재가’와 ‘입찰 내역’을 확인할 수 있게 되었습니다.

  WebSocket을 활용하여 불필요한 HTTP 요청을 줄이고, 서버-클라이언트 간의 즉각적인 데이터 전송이

  가능해졌습니다.
  
 
</details>



<details>
  <summary> <strong>🔹 다중 서버 환경에서의 실시간 데이터 공유 문제</strong> </summary>
<br>
  [문제 인식]

- WebSocket 연결은 기본적으로 각 서버에 독립적으로 유지되므로, 다중 서버 환경에서 하나의 서버에서 발생한

  입찰 내역 반환이 다른 서버에서는 반영되지 않는 문제가 발생할 수 있습니다. 이러한 구조에서는

  다중 서버 환경에서 실시간성이 중요한 경매 시스템을 운영할 때, 서버 간 데이터 동기화가 원활하게

  이루어지지 않는 문제가 있었습니다. 

[해결 방안]

- STOMP(WebSocket) 적용
  
     STOMP를 활용하면 메시지를 특정 주제(topic)로 구독할 수 있어 현재가와 입찰 내역을 효율적으로

    전달할 수 있습니다.
  
- Redis Pub/Sub 연동
  
   각 서버가 Redis의 Pub/Sub을 활용해 메시지를 발행(Publish)하고, 다른 서버에서 이를 구독(Subscribe)하여

    반영하도록 구성했습니다.

[해결 과정]

- STOMP + Redis Pub/Sub 활용
  
   STOMP를 사용하여 WebSocket 기반의 메시징을 관리하고, Redis의 Pub/Sub 기능을 활용하여 서버 간 메시지를

   실시간으로 동기화하도록 아래와 같은 흐름으로설계했습니다.
    
  <img src="https://github.com/user-attachments/assets/1e82fef9-888c-46e3-aad9-4d88aaa6a98f" height=350px >


- Redis를 선택한 이유
  
   Kafka, RabbitMQ, ActiveMQ 등의 메시지 큐도 고려할 수 있었지만, 해당 기술에 대한 러닝 커브가 존재하여

  빠른 도입이 어려울 것으로 판단했습니다. 기존에 사용 경험이 있는 Redis를 활용하면 구현 속도를 높이고,

  시스템 안정성을 유지할 수 있습니다. 또한 기존에 Caffeine 캐시를 사용하던 ‘탈퇴한 회원의 블랙리스트’ 문제를

  다중 서버 환경에 적용을 하면서 문제가 생긴 부분이 있었는데 그곳에 Redis 캐시를 쓰기로 결정해, Redis를

  선택했습니다.

[해결 결과]

- 다중 서버 환경에서도 정보의 실시간성을 유지할 수 있게 되었습니다.
  
</details>


<details>
  <summary> <strong>🔹 Redis에서 LocalDateTime의 직렬화/역직렬화 문제</strong> </summary>
  <br>

  [문제 인식]

- Spring Boot에서 STOMP + Redis Pub/Sub 기능을 사용하여 실시간 통신을 구현하려 할 때 LocalDateTime을 

   저장하고 불러오는 과정에서 직렬화/역직렬화 오류가 발생했습니다.

   com.fasterxml.jackson.databind.exc.InvalidDefinitionException 예외가 발생했으며,

   이는 Jackson이 기본적으로 LocalDateTime을 처리하지 못하기 때문에 발생한 문제였습니다.

[해결 방안]

- LocalDateTime을 Redis에 저장하고 불러올 수 있도록, 직렬화/역직렬화가 가능한 라이브러리를 추가하고

  변환 방식을 명시적으로 지정했습니다. 이를 위해 jackson-datatype-jsr310 라이브러리를 추가하고,

  @JsonSerialize, @JsonDeserialize 어노테이션을 활용하여 LocalDateTime을 변환할 수 있도록 설정했습니다.

[해결 과정]

1. jackson-datatype-jsr310 라이브러리 추가

```java
dependencies {
    implementation 'com.fasterxml.jackson.datatype:jackson-datatype-jsr310:2.13.3'
}
```

1. 필드에 @JsonSerialize, @JsonDeserialize을 지정함으로써 직렬화/역직렬화 방식 지정

```java
    @JsonSerialize(using = LocalDateTimeSerializer.class)
    @JsonDeserialize(using = LocalDateTimeDeserializer.class)
    @JsonFormat(pattern = "yyyy-MM-dd HH:mm:ss")
    private LocalDateTime createdAt;
```

[해결 결과]

- Redis에서 LocalDateTime을 저장하고 불러오는 과정에서 발생하는 직렬화 오류를 해결했습니다.
  
- LocalDateTimeSerializer, LocalDateTimeDeserializer를 적용하여 yyyy-MM-dd HH:mm:ss 형식으로 변환하여 반환 타입을 통일하였습니다.
  
- jackson-datatype-jsr310 모듈을 사용하여 Java 8 날짜/시간 API를 안전하게 처리할 수 있도록 개선하였습니다.
  
</details>
<details>
  <summary> <strong>🔹 쿼리 횟수, 불 필요한 데이터 조회</strong> </summary>
  <br>
	
  [문제 인식]

1. 조회 기능 테스트를 해보고자 Postman을 이용한 검색 실행
   
3. 조회 1번에 4번의 쿼리문이 발생하고, 불필요한 컬럼까지 조회되는 것을 발견

<img src="https://github.com/user-attachments/assets/d0c0cc17-d673-4941-8ba0-fc88057c6847" height=300px width=750px>



[해결 방안]

1. 조인을 이용하여 불필요한 쿼리가 발생하지 않도록 수정
2. 기존에 auction에 대한 모든 컬럼을 조회하도록 되어있던 코드를 필요한 컬럼만 조회하도록 코드 수정
    

[해결 과정]

<img src="https://github.com/user-attachments/assets/ba075bc3-98ff-4253-97ce-2b9bc4e5b8c3" height=350px width=450px>

<br>
<img src="https://github.com/user-attachments/assets/4a84d8db-6461-4e3a-bc81-0d8d9f4c6d3d" height=350px width=450px>


[해결 결과]

<img src="https://github.com/user-attachments/assets/7135b51e-996b-44e9-a584-a5e0afcd8c0e" height=700px width=450px>

  
</details>

<details>
  <summary> <strong>🔹 인덱싱, Full text index</strong> </summary>
  <br>

  [문제 인식]

- QueryDSL에서는 RDBMS표준을 따르기 때문에 MySQL의 비 표준 기능인

   MATCH…AGAINST를 사용하려면 사용자가 직접 함수를 등록하여 사용할 수 있게 해줘야 했으며,

   그렇기 때문에 함수 등록하는 방법을 찾아본 결과 CustomDialect를 만들어서 사용하는 방법을

   알게 되었고 적용하던 도중에 아래와 같이 더 이상 지원하지 않는 기능이라는 문제가 생겼습니다.

   <img src="https://github.com/user-attachments/assets/23d244eb-0dbc-41da-b5de-f1afb60214e5" height=350px width=600px>


[해결 방안]

- 저와 같은 문제를 직면한 사람들이 작성한 기술 블로그를 참고하여 다른 방식을 이용해 보았습니다. 

   FunctionContributor를 implements하여 구현하는 방식이었습니다. 

[해결 과정]

1. CustomFunctionContributor 생성
    
    ```java
    public class CustomFunctionContributor implements FunctionContributor {
    
        @Override
        public void contributeFunctions(FunctionContributions functionContributions) {
            //resultType은 DOUBLE타입이며,functionContributions 는 사용자가 정의 
            //함수를 등록 할 수 있게 해주는 것
            BasicType<Double> resultType = functionContributions
                    // 타입 설정 정보를 가지고오는 메서드
                    .getTypeConfiguration()
                    //기본적인 데이터 타입들을 관리하는 레지스트리, 하이버네이트가 
                    //지원하는 기본 데이터 타입에 대한 정보를 저장하고 제공함
                    .getBasicTypeRegistry()
                    //DOUBLE타입에 대한 basicType객체를 반환
                    .resolve(StandardBasicTypes.DOUBLE);
    
            //전체정리 : 하이버네이트의 기본 타입 레지스트리에서 DOUBLE타입에 대한 
            //정보를 가지고 오는과정
    
            //사용자 정의 함수를 등록
            functionContributions.getFunctionRegistry()
                    //함수의 이름은 "match_against"이며, 실제 쿼리에서 사용하는 
                    //형식의 패턴을 등록
                    .registerPattern(
                    "match_against", "match(?1) against (?2 in boolean mode)",
                            resultType);
    
        }
    }
    ```
    

[해결 결과]

- 위와 같은 방법으로 사용자 정의 함수를 등록 후 QueryDSL에 적용해 보았고, 검색 했을 때 발생하는 쿼리문에

  잘 적용되어있는 것을 확인 했습니다.

[추후 작업 계획]

- 꼭 QueryDSL을 위해서가 아닌 다른 방면에서도 사용할 수 있는 사례가 있을 것이라 생각하고 조금 더 자세히

  공부 해볼 예정이며, 이러한 기능을 모르는 동기들에게 알려주는 것도 다같이 성장할 수 있는

  좋은 방법일 것 같습니다.
  
    
</details>

<details>
  <summary> <strong>🔹 CountQuery</strong> </summary>
  <br>

  [문제 인식]

- FTS(Full Text Search)적용 후 응답 속도를  확인하던 도중 오히려 응답 속도가 지연된 것을 

   확인하게 되었고, 원인을 파악하고자 DB SQL 콘솔창을 이용하여 조회 쿼리와 카운트 

   쿼리를 따로 테스트 해보았습니다. 그리고 카운트 쿼리에서 많은 시간이 

   소모되고 있다는 것을 확인하게 되었습니다.

   <img src="https://github.com/user-attachments/assets/2cbbe9d7-74a8-473e-b3e3-1ba2cbc740a7" height=350px width=450px>



[해결 방안]

- FTS(Full Text Search)로 인해 카운트 쿼리의 속도가 지연되고 있다는 것을 확인하였고, 카운트 쿼리 부분은

  조회하여 데이터를 불러오는 것이 목적이 아닌 수를 헤아리는 것이 목적이라는 것에 초첨을 맞추어

  카운트 쿼리용 메서드를 like연산자를 이용해 생성하여 적용해 주었습니다. 왜 카운트 쿼리는 like연산자를

  이용하는 것이 빠른가에 대하여 FTS(Full Text Search)는 특정 검색어에 대해 검색을 진행하면서 위치는 어디인지,

  검색어와 얼만큼 유사한지, 관련성에 대한 점수는 몇 점인지 까지 확인하는 과정이 모두 포함되어 있어 속도가

  오히려 늦어진 다는 점을 알게 되었습니다. like연산자를 이용하여 풀 스캔을 해서 조건에 해당하는 값이 있으면

  바로 카운팅을 하는것이 더 빠르겠다고 판단하였습니다. 카운트 쿼리 부분은 조회하여 데이터를 불러오는 것이 목적이

  아닌 수를 헤아리는 것이 목적이라는 것에 초첨을 맞추어 카운트 쿼리용 메서드를 like연산자를 이용해 생성하여

  적용해 주었습니다. 

[해결 과정]

1. 카운트쿼리용 메서드 생성
    
    ```java
    private BooleanExpression countKeyboard(String keyboardName) {
            if (keyboardName == null) {
                return null;
            }
    
            return auction.keyboard.name.like("%" + keyboardName + "%");
        }
    ```
    
2. 카운트 쿼리에 적용
    
    ```java
    Long totalCount = Optional.ofNullable(queryFactory.select(
                            auction.count())
                    .from(auction)
                    .leftJoin(auction.keyboard, keyboard)
                    .leftJoin(auction.member, member)
                    .where(
                            countKeyboard(keyboardName),
                            countAuctionTitle(auctionTitle),
                            countSeller(sellerName),
                            auctionStatus(auctionStatus),
                            auctionStartDate(startDate),
                            auctionEndDate(endDate)
                    )
                    .fetchOne()).orElse(0L);
    ```
    

[해결 결과]

- 카운트 쿼리의 응답 속도가 77.09% 개선된 것을 확인 할 수 있었습니다.

   <img src="https://github.com/user-attachments/assets/8e4567ca-d3d1-4f79-9b8f-bea7d00e5fbb" height=350px width=450px>


[추후 작업 계획]

- CountQuery에서의 응답 속도를 개선하고자 like연산자를 사용하였지만, 조회 쿼리와 카운트 쿼리에서 where절의

  조건이 다르면 결과 값이 다를 수 있기 때문에 해당 방법은 적합하지 않다고 판단하였습니다. 하여 다른 방법이

  있는지 추가적으로 찾아볼 예정이며, 카운트 쿼리의 필요성에 대해서 잠시 고민을 해보았을 때  

  1. 프론트에서 카운트쿼리의 연관성이 무엇이 있을까
  2. 만일 현업이였다면 기획 의도에 따라 필요할 수 있지 않을까

   라는 질문을 하게 되었고, 이에 대한 자료들을 조금 더 찾아 보고, 다른 사람들의 의견을 들어볼 예정입니다.
  

</details>

<details>
  <summary> <strong>🔹 트랜잭션의 롤백, 매우 긴 응답 시간</strong> </summary>
  <br>
  [문제 정의]

1. 결제 영수증를 위해 결제 기능에 이메일을 보내는것을 추가하였는데 이메일에 문제가 있어서 보내는 것에
  
   실패하자 결제데이터 자체가 데이터베이스에 저장되지 않는 것을 확인했습니다. 이메일이 가지 않아도

   정상 결제를 완료한 상황에서 결제가 아예 취소되는 것은 로직이 이상한 것이라고 생각되었습니다
   
      <img src="https://github.com/user-attachments/assets/80dc7c9c-7858-4f28-b9e3-616836d6175f" height=350px >


2. 이메일을 보내는데 성공했으나 요청 응답 시간이 이메일 전송이 이루어지지 않을 때에는 200ms에서 이메일을
  
   전송하게 하자 4s로 증가한 것을 확인했습니다. 위의 문제처럼 아예 결제가 안되는 등의 큰 문제는

   아닐 수 있으나, 사용자가 무려 4초간 로딩 화면을 봐야한다는 것이므로 UX에 문제가 생긴다고 생각했습니다.
    
   
     <img src="https://github.com/user-attachments/assets/f90b611f-e626-491d-8744-ab7fe75ec7ad" height=350px >
   

[가설]

1. 한 트랜잭션 안에서 이메일과 결제 저장이 함께 이루어지고 있기 때문에 이메일이 보내지지 않으면 결제도 실패한다.
2. 마찬가지로 한 API에서 생성과 이메일 전송이 함께 이루어지고 있기 때문에 이메일이 보내질때까지  API 응답이 이루어지지 않는다.

[해결 방안(가설)]

1. 한 트랜잭션 안에서 이메일과 결제 저장이 함께 이루어지고 있기 때문에 이메일이 보내지지 않으면
  
   결제도 실패한다.
    
2. 마찬가지로 한 API에서 생성과 이메일 전송이 함께 이루어지고 있기 때문에 이메일이 보내질때까지 API 응답이
  
   이루어지지 않는다.
    

**∴  이메일과 이벤트의 저장을 분리하면 해결될 것이다.**

[해결 과정]

```java
 @Async
    public void sendMemberEmail(Long memberId, MemberEmailRequestDto memberEmailRequestDto) {
        Member member = memberRepository.findById(memberId)
                .orElseThrow(() -> new DataNotFoundException(ErrorCode.NOT_FOUND_MEMBER,
                        ErrorMessageParameter.MEMBER));

       ...
    }
```

1. 이메일 보내는것에 실패해도 저장되고, 요청도 정상적으로 나오고 응답시간도 줄어드는 것을 확인했습니다.
        
   <img src="https://github.com/user-attachments/assets/09c41cfa-758e-4437-a244-77d023284417" height=350px >
   
   <img src="https://github.com/user-attachments/assets/fe2a53c3-e032-430a-961e-e01c145e151b" height=150px width=650px >


[해결 결과]

- 결과
  
   비동기로 실행했을때, 이메일이 실패해도 결제나 경매 등이 저장되고 이메일의 전송을 기다리지 않고 응답하기

   때문에 응답시간도 줄어든것을 확인할 수 있습니다.
    
- 전후 데이터 비교
  
  동기로 실행되었을때 응답 속도가 4.02s였던데 반해 비동기로 실행되었을 때, 48ms로 응답 속도가 98.93%

  향상되었습니다.

</details>

<details>
  <summary> <strong>🔹 이벤트가 실패했을 때 이메일의 전송</strong> </summary>
<br>
[문제 정의]

- 비동기로 이메일 전송이 트랜잭션과 관계가 없도록하자 반대로 트랜잭션이 길어지면 트랜잭션이 실패해도

  이메일은 전송되는 문제가 발생하였습니다.

[해결 방안(가설)]

- `@Async`는 새로운 스레드에서 실행되므로 트랜잭션과 별개로 동작한다. `emailService.sendMemberEmail()`은

  `@Async`로 실행되므로,부모 메서드의 트랜잭션을 이어받지 않습니다. 즉, 트랜잭션이 `commit`되지 않은 상태에서

   실행될 가능성이 있다. 트랜잭션이 `commit`되지 않은 상태이므로, 데이터를 제대로 읽지 못할 가능성이 있다.

   주 트랜잭션이 롤백되면, 이메일이 전송된 상태가 되면서 데이터 정합성 문제가 발생할 수 있다.

   **∴  트랜잭션이 끝난 후, 이메일을 전송하도록 보장하면 해결될 것이다.**

[해결 과정]
- `@TransactionalEventListener`을 사용하여 이벤트 기반으로 변경하였습니다.

1. 이메일을 전송해야할 이벤트가 발생했을때, `ApplicationEventPublisher`를 사용해 
    
    **이메일 전송 이벤트(AuctionCreatedEvent)를 발행**하도록 수정했습니다.
    

```java
@Transactional
    public void createPayment(String jsonBody, Long memberId) {
       ...
        MemberEmailRequestDto emailRequestDto = new MemberEmailRequestDto(
                Constants.PAYMENT_COMPLETION_EMAIL_TITLE,
                String.format(Constants.PAYMENT_COMPLETION_EMAIL_CONTENTS, payment.getAmount(),
                        payment.getPaymentMethod()
                )
        );
        applicationEventPublisher.publishEvent(
                new EmailEvent(payment.getMember().getId(), emailRequestDto));
    }
```

2. 이벤트 리스너에서 트랜잭션 종료 후 이메일을 전송하도록 했습니다.
    
```java
    public class EmailEventListener {
        private final EmailService emailService;
        @Async
        @TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT)
        public void handleEmailEvent(EmailEvent event) {
            emailService.sendMemberEmail(event.getMemberId(), event.getEmailRequestDto());
        }
    }
    
```
    

[해결 완료]

- 결과
	- 트랜잭션이 롤백되면 이메일이 전송되지 않고, 트랜잭션이 성공한 경우에만 정상적으로
    
       이메일이 전송됩니다.
    
- 전후 데이터 비교
	- 이벤트 리스너를 사용하기 전 3.92s에서 사용후 4.19s로 6.89% 속도가 느려진 것을
    
       확인할 수 있었습니다. 그러나 7%정도의 차이라면 트랜잭션이 완료된 후에만 이메일을 
    
       전송할 수 있도록 보장할 수 있다는 점에서 적용할 가치가 있다고 판단하였습니다.

  <img src="https://github.com/user-attachments/assets/611a9119-446c-4f10-be00-c879e82873cd" height=100px width=700px >

  <img src="https://github.com/user-attachments/assets/3ad61ce9-f4f5-46db-9922-c716c374fc52" height=100px width=700px >

</details>

<details>
  <summary> <strong>🔹 경매의 현재가가 예상가와 다른 문제</strong> </summary>
  <br>

  **[문제 인식]**

- 경매 입찰 과정에서 동시에 다수의 요청이 들어올 경우, 특정 사용자의 입찰 내용이
    
    정상적으로 반영되지 않는 문제가 발생했습니다. 모든 입찰이 처리되었다는 응답을 
    
    받았음에도 불구하고 최종적으로 경매의 현재가가 예상과 다르게 기록되는 오류가 
    
    확인되었습니다.

   <img src="https://github.com/user-attachments/assets/53ccee34-c164-4fa6-b254-c1be164eb95d" height=150px width=700px >


**[해결 방안]**

- 경매의 현재가는 여러 입찰 요청에 의해 업데이트되는데, 다수의 요청이 거의 동시에
    
    처리되면서 충돌이 발생한 것으로 예상했습니다. 이를 해결하기 위해 동시성 제어 방안을 
    
    검토한 결과, 낙관적 락과 비관적 락을 고려할 수 있었습니다.
    

- 낙관적 락은 충돌이 발생하지 않으면 문제가 없지만, 다수의 요청이 많은 입찰에서 충돌이

  잦아질 가능성이 높습니다. 충돌이 발생하면 롤백 후 재시도를 수행해야 하므로 

  성능 저하가 발생할 수 있다는 점이 문제였습니다. 

- 비관적 락은 트랜잭션이 시작되면 해당 데이터에 대한 다른 트랜잭션의 접근을 제한하여

  데이터 정합성을 강력하게 보장할 수 있습니다. 그러나 규모가 큰 경매에서는 락 경합으로 

  인해 성능 저하가 발생할 가능성이 있습니다.

다만, 저희 경매 프로젝트에서는 입찰 시 경매당 입찰 횟수를 10회로 제한하기 때문에 불필요한

경합 발생을 방지할 수 있다고 생각하여 원래 목표였던 여러 사용자가 동시에 입찰하더라도 

데이터 정합성이 유지되어야 한다는 것을 우선시하였습니다. 이에 따라, 확실한 정합성을 

유지할 수 있도록 비관적 락을 적용하기로 결정했습니다.

<img src="https://github.com/user-attachments/assets/6c8675f2-ec51-4c47-a274-b8d2b5b5d49e" height=350px >


**[해결 과정]**

- 경매 조회시, 비관적 락을 적용하여 동시성을 제어할 수 있도록 했습니다.

```java
// AuctionRepository에서 @Lock(LockModeType.PESSIMISTIC_WRITE) 사용하여 경매 객체를 조회할 때 비관적 락 적용
    @Lock(LockModeType.PESSIMISTIC_WRITE)
    @Query("SELECT a FROM Auction a WHERE a.id = :auctionId")
    Optional<Auction> findByIdWithPessimisticLock(@Param("auctionId") Long auctionId);
```

**[해결 결과]**

- 비관적 락을 적용하기 전후의 성능을 비교한 결과, 처리 시간이 약 27.6% 증가했지만,
    
    입찰 요청이 동시에 들어오더라도 정합성이 유지되며, 최종 경매가가 정상적으로 반영됨을
    
    확인했습니다.

  <img src="https://github.com/user-attachments/assets/42b0619e-a77d-4955-82e4-3b1f794031a1" height=150px width=700px >
 
</details>




<details>
  <summary> <strong>🔹 EC2 환경에서 화면 이동이 정상적으로 동작하지 않는 문제</strong> </summary>
<br>

  [문제 인식]

- 결제 기능 구현을 위해 작성한 html 파일로의 이동이 로컬 환경에서는 정상 작동 했으나 EC2 환경에서는

  404 에러가 발생했습니다.

```java
@GetMapping
public String methodA() {
	return "/process"; // ec2에서 에러 발생
}
```

[해결 방안]

- ViewResolver가 제대로 된 경로(`src/main/resources/templates/`)에서 html 파일을 찾을 수 있도록

  설정 파일 확인하기
    - ViewResolver를 위한 설정 파일을 만들거나 별도의 설정을 변경한 적이 없기 때문에 원인이 될 수 없습니다.
    
- SpringBoot의 동작 방식 및 OS의 파일 경로 처리 방식 확인하기
    - Thymeleaf의 ViewResolver는 `prefix + viewName + suffix` 방식으로 동작하며, 기본적으로 `classpath:/templates/` 에서 View를 찾습니다.
      
    - Windows에서는 `C:\projects\myapp\templates\process.html` 같은 경로 구조를 가지지만,
    Linux에서는 `/home/ec2-user/app/templates/process.html` 같은 경로 구조를 가집니다.

    - Linux에서는 `/` 가 붙으면 파일 시스템의 **절대 경로**로 처리하려고 시도할 가능성이 있기 때문에 루트
    
      디렉토리로 해석될 가능성이 있습니다.
    - 그렇기 때문에 Linux 환경에서도 **상대 경로**로 해석할 수 있도록 `/` 를 제외했습니다.

[해결 과정]

- 컨트롤러에서 리턴하는 값을 절대 경로( `/process` )로 설정 하지 않고 상대 경로(`process` )로 설정하였습니다.

```java
@GetMapping
public String methodA() {
	return "process";
}
```

[해결 결과]

- EC2 환경에서도 로컬 환경과 동일하게 결제 기능에 필요한 화면 이동이 가능해졌습니다.
  
</details>

<details>
  <summary> <strong>🔹 스케줄러에 등록된 작업의 작업량에 따른 스케줄 지연 문제</strong> </summary>
<br>

[문제 인식]

- 스케줄러를 사용하여 1시간 마다 경매 시작/종료를 자동으로 설정했습니다. 하지만 @Scheduled는

  싱글 스레드로 동작하기 때문에 경매 시작의 작업량이 많다면 경매 종료가 영향을 받을 수 있다는 생각을

  하게 되었습니다.
    
    📢 아래 사진은 테스트를 위하여 스케줄러를 1분 마다 실행되도록 설정하였으며, 작업량이 많다는 것을

     대체하기 위해 `Thread.sleep(61000)` 을 사용했습니다.
    
- 그 결과 경매 시작은 정상적으로 동작하지 못하였습니다.
    - 경매 종료가 먼저 실행되고 `Thread.sleep(61000)`에 걸려서 경매 시작은 실행되지 않았습니다.
    - 그 후의 스케줄러에서 경매 시작에 해당하는 작업은 없기 때문에 상태가 변경되지 않았습니다.
   <img src="https://github.com/user-attachments/assets/187ef773-b440-4dd9-b4ed-5b48b52ae356" height=150px width=700px >

   <img src="https://github.com/user-attachments/assets/b47e4ef9-07ae-4dce-aa9d-e93b5b30b429" height=150px width=700px >

   [해결 방안]

- 각각의 작업이 다른 스레드에서 동작할 수 있도록 하기
    - `ThreadPoolTaskScheduler` 를 사용하여 별도의 스레드 풀을 생성합니다.
        - 공식 문서에 따르면 `ThreadPoolTaskScheduler` 를 사용할 경우 실행 스레드가 아닌
            
            스케줄러 스레드에서 task가 동작한다고 설명되어 있습니다.
            
        - 별도의 스레드에서 동작하게 되면 스케줄러의 작업에 대해 보장할 수 있다는 장점이
            
            생긴다고 생각했습니다.
     
            [📚 Spring Framework 6.2.3 API](https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/scheduling/concurrent/ThreadPoolTaskScheduler.html)
            
            

[해결 과정]

- config 파일을 작성하여 스케줄러를 위한 스레드 풀을 생성했습니다.
- 동시에 실행 될 가능성이 있는 작업이 2개뿐이기 때문에 현재 `SCHEDULER_THREAD_POOL_SIZE` 는 2입니다.

```java
@Configuration
public class SchedulerConfig implements SchedulingConfigurer {

    @Override
    public void configureTasks(ScheduledTaskRegistrar taskRegistrar) {
        taskRegistrar.setScheduler(customTaskScheduler());
    }

    @Bean
    public ThreadPoolTaskScheduler customTaskScheduler() {
        ThreadPoolTaskScheduler scheduler = new ThreadPoolTaskScheduler();
        scheduler.setPoolSize(Constants.SCHEDULER_THREAD_POOL_SIZE);
        scheduler.initialize();

        return scheduler;
    }
}
```

[해결 결과]

- 스케줄러에 등록된 작업이 동일한 시간으로 설정 되어도 해결할 수 있는 방법을
    
    알게 되었습니다.
    
    📢 아래 사진은 테스트를 위하여 스케줄러를 1분 마다 실행되도록 설정하였으며, 작업량이 많다는 것을

     대체하기 위해 `Thread.sleep(61000)` 을 사용했습니다.

    <img src="https://github.com/user-attachments/assets/3db63467-2b4b-4209-88af-75a3d2744fb2" height=150px width=700px >
  
    <img src="https://github.com/user-attachments/assets/58ba78af-d1ca-40d3-b8de-27c43c0921f2" height=250px width=700px >

[추후 작업 계획]

- 현재 인스턴스를 2개 사용하여 분산 환경을 만들었는데 스케줄러가 모든 인스턴스에서
    
    실행되고 있는 문제가 발생하고 있습니다.
    
    이에 따라 스케줄러가 모든 인스턴스에서 실행되지 않게 하거나, 별도의 스케줄러 서버를
    
    마련할 생각입니다.


</details>




<br>

## 😊추가로 도전, 개선해 보고싶은 것😊

`인프라 구성 개선`, `동시성 제어 개선`, `이메일 기능 개선(안정성)`, `스케줄링 기능 보완`

`중복 코드 및 동일한 라이브러리로 구현 가능한 기능 리팩토링`, 

`검색 기능 개선(엘라스틱 서치 or 다른 라이브러리 알아보기`



<br>

## 😘사탕팔이와 아이들!!!😘
<img src="https://github.com/user-attachments/assets/7df97370-11c3-4e61-bf2c-b5618063e4fe" height=200px width=250px >

# 


| 이름 | 깃허브 |
| --- | --- |
| 홍은기 | [star-pooh](https://github.com/star-pooh) |
| 임희현 | [HEEHYUN0221](https://github.com/HEEHYUN0221?tab=repositories) |
| 장지원 | [ijnow](https://github.com/ijnow) |
| 송진솔 | [solaaac](https://github.com/solaaac) |
| 신가을 | [Shin-Gaeul](https://github.com/Shin-Gaeul) |

<br> <br>


